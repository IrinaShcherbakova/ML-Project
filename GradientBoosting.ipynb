{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"preprocessed_train_data.csv\", index_col = 0)\n",
    "test = pd.read_csv(\"preprocessed_test_data.csv\", index_col = 0)\n",
    "\n",
    "trained_tweets = train['keyword']+train['text']\n",
    "test_tweets = test['keyword']+test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# X_train = scaler.fit_transform(trained_tweets)\n",
    "# X_test = scaler.transform(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 12  \n",
    "test_size = 0.30\n",
    "  \n",
    "X_train, X_test, y_train, y_test = train_test_split(trained_tweets, train['target'],  \n",
    "    test_size=test_size, random_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5329, 44132) (2284, 44132)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 3),\n",
    "    lowercase=True,\n",
    "    min_df=5,\n",
    "    max_features=30000)\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(3, 6),\n",
    "    lowercase=True,\n",
    "    min_df=5,\n",
    "    max_features=50000)\n",
    "\n",
    "vectorizer = FeatureUnion([('word_vectorizer', word_vectorizer),  ('char_vectorizer', char_vectorizer)])\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "X_train_vectors = vectorizer.transform(X_train).toarray()\n",
    "X_test_vectors = vectorizer.transform(X_test).toarray()\n",
    "print(X_train_vectors.shape, X_test_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.566\n",
      "Accuracy score (validation): 0.586\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.568\n",
      "Accuracy score (validation): 0.588\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.569\n",
      "Accuracy score (validation): 0.590\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.606\n",
      "Accuracy score (validation): 0.622\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.609\n",
      "Accuracy score (validation): 0.623\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.610\n",
      "Accuracy score (validation): 0.624\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.610\n",
      "Accuracy score (validation): 0.624\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(X_train_vectors, y_train)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train_vectors, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test_vectors, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.609\n",
      "Accuracy score (validation): 0.629\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.636\n",
      "Accuracy score (validation): 0.650\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.661\n",
      "Accuracy score (validation): 0.668\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.739\n",
      "Accuracy score (validation): 0.721\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.767\n",
      "Accuracy score (validation): 0.734\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.766\n",
      "Accuracy score (validation): 0.728\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.769\n",
      "Accuracy score (validation): 0.718\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=20, max_depth=5, random_state=0)\n",
    "    gb_clf.fit(X_train_vectors, y_train)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train_vectors, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test_vectors, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.869\n",
      "Accuracy score (validation): 0.765\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.903\n",
      "Accuracy score (validation): 0.746\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.911\n",
      "Accuracy score (validation): 0.747\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.910\n",
      "Accuracy score (validation): 0.731\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=100, max_depth=10, random_state=0)\n",
    "    gb_clf.fit(X_train_vectors, y_train)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train_vectors, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test_vectors, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.797\n",
      "Accuracy score (validation): 0.756\n",
      "F1 Score: 0.623\n",
      "Recall: 0.486\n",
      "Precision: 0.867\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.835\n",
      "Accuracy score (validation): 0.772\n",
      "F1 Score: 0.665\n",
      "Recall: 0.545\n",
      "Precision: 0.852\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.854\n",
      "Accuracy score (validation): 0.779\n",
      "F1 Score: 0.687\n",
      "Recall: 0.583\n",
      "Precision: 0.835\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.920\n",
      "Accuracy score (validation): 0.782\n",
      "F1 Score: 0.713\n",
      "Recall: 0.650\n",
      "Precision: 0.789\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.966\n",
      "Accuracy score (validation): 0.757\n",
      "F1 Score: 0.688\n",
      "Recall: 0.647\n",
      "Precision: 0.736\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.974\n",
      "Accuracy score (validation): 0.762\n",
      "F1 Score: 0.701\n",
      "Recall: 0.671\n",
      "Precision: 0.734\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.976\n",
      "Accuracy score (validation): 0.749\n",
      "F1 Score: 0.690\n",
      "Recall: 0.674\n",
      "Precision: 0.707\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=learning_rate, max_features=60, max_depth=6, random_state=0)\n",
    "    gb_clf.fit(X_train_vectors, y_train)\n",
    "    \n",
    "    predictions = gb_clf.predict(X_test_vectors)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train_vectors, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test_vectors, y_test)))\n",
    "    print(\"F1 Score: {0:.3f}\".format(f1_score(y_test,predictions)))\n",
    "    print(\"Recall: {0:.3f}\".format(recall_score(y_test,predictions)))\n",
    "    print(\"Precision: {0:.3f}\".format(precision_score(y_test,predictions)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.954\n",
      "Accuracy score (validation): 0.793\n",
      "F1 Score: 0.720\n",
      "Recall: 0.642\n",
      "Precision: 0.820\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.976\n",
      "Accuracy score (validation): 0.790\n",
      "F1 Score: 0.721\n",
      "Recall: 0.653\n",
      "Precision: 0.805\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.986\n",
      "Accuracy score (validation): 0.789\n",
      "F1 Score: 0.723\n",
      "Recall: 0.664\n",
      "Precision: 0.795\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.989\n",
      "Accuracy score (validation): 0.786\n",
      "F1 Score: 0.721\n",
      "Recall: 0.667\n",
      "Precision: 0.785\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.989\n",
      "Accuracy score (validation): 0.782\n",
      "F1 Score: 0.719\n",
      "Recall: 0.672\n",
      "Precision: 0.773\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.989\n",
      "Accuracy score (validation): 0.773\n",
      "F1 Score: 0.706\n",
      "Recall: 0.657\n",
      "Precision: 0.763\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.988\n",
      "Accuracy score (validation): 0.763\n",
      "F1 Score: 0.696\n",
      "Recall: 0.652\n",
      "Precision: 0.745\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=learning_rate, max_features=70, max_depth=20, random_state=0)\n",
    "    gb_clf.fit(X_train_vectors, y_train)\n",
    "    \n",
    "    predictions = gb_clf.predict(X_test_vectors)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train_vectors, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test_vectors, y_test)))\n",
    "    print(\"F1 Score: {0:.3f}\".format(f1_score(y_test,predictions)))\n",
    "    print(\"Recall: {0:.3f}\".format(recall_score(y_test,predictions)))\n",
    "    print(\"Precision: {0:.3f}\".format(precision_score(y_test,predictions)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.03\n",
      "Accuracy score (training): 0.961\n",
      "Accuracy score (validation): 0.787\n",
      "F1 Score: 0.714\n",
      "Recall: 0.640\n",
      "Precision: 0.806\n",
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.982\n",
      "Accuracy score (validation): 0.789\n",
      "F1 Score: 0.723\n",
      "Recall: 0.664\n",
      "Precision: 0.794\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.989\n",
      "Accuracy score (validation): 0.797\n",
      "F1 Score: 0.735\n",
      "Recall: 0.677\n",
      "Precision: 0.804\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.989\n",
      "Accuracy score (validation): 0.791\n",
      "F1 Score: 0.727\n",
      "Recall: 0.673\n",
      "Precision: 0.792\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.989\n",
      "Accuracy score (validation): 0.775\n",
      "F1 Score: 0.709\n",
      "Recall: 0.660\n",
      "Precision: 0.766\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.989\n",
      "Accuracy score (validation): 0.777\n",
      "F1 Score: 0.714\n",
      "Recall: 0.671\n",
      "Precision: 0.763\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.989\n",
      "Accuracy score (validation): 0.761\n",
      "F1 Score: 0.700\n",
      "Recall: 0.671\n",
      "Precision: 0.731\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-fa256a3caa25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlr_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgb_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgb_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1544\u001b[0m         n_stages = self._fit_stages(\n\u001b[1;32m   1545\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1546\u001b[0;31m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1608\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[1;32m   1609\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1242\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1244\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#####Highest is 0.075 with validation accuracy 0.797\n",
    "\n",
    "lr_list = [0.03, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=120, learning_rate=learning_rate, max_features=100, max_depth=25, random_state=0)\n",
    "    gb_clf.fit(X_train_vectors, y_train)\n",
    "    \n",
    "    predictions = gb_clf.predict(X_test_vectors)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train_vectors, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test_vectors, y_test)))\n",
    "    print(\"F1 Score: {0:.3f}\".format(f1_score(y_test,predictions)))\n",
    "    print(\"Recall: {0:.3f}\".format(recall_score(y_test,predictions)))\n",
    "    print(\"Precision: {0:.3f}\".format(precision_score(y_test,predictions)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.989\n",
      "Accuracy score (validation): 0.797\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1179  157]\n",
      " [ 306  642]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.84      1336\n",
      "           1       0.80      0.68      0.73       948\n",
      "\n",
      "    accuracy                           0.80      2284\n",
      "   macro avg       0.80      0.78      0.79      2284\n",
      "weighted avg       0.80      0.80      0.79      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=120, learning_rate=0.075, max_features=100, max_depth=25, random_state=0)\n",
    "gb_clf.fit(X_train_vectors, y_train)\n",
    "    \n",
    "predictions = gb_clf.predict(X_test_vectors)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train_vectors, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test_vectors, y_test)))\n",
    "print()\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (/Users/nihal/anaconda3/lib/python3.7/site-packages/sklearn/metrics/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9f6772d24880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Plot non-normalized confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (/Users/nihal/anaconda3/lib/python3.7/site-packages/sklearn/metrics/__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = train['target'].target_names\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(gb_clf, X_test_vectors, y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
